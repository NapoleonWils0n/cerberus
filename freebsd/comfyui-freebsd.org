#+STARTUP: content
* comfyui
** verify and setup cuda

[[https://github.com/verm/freebsd-stable-diffusion?tab=readme-ov-file]]

This involves two steps the first is to install nv-sglrun in order to check for CUDA support which only works for FreeBSD binaries. The second step is to build uvm_ioctl_override.c to have the same work for Linux binaries.

This work has been done by shkhln you can see his work here libc6-shim. We will not use this directly but the version used for Linux binaries below.

Install libc6-shim to get the nvidia-sglrun binary.

#+begin_src sh
doas pkg install libc6-shim
#+end_src

First install linux-c7-devtools.

#+begin_src sh
doas pkg install linux-c7-devtools
#+end_src

#+begin_src sh
doas pkg install linux-c7-libglvnd
#+end_src

#+begin_src sh
fetch https://gist.githubusercontent.com/shkhln/40ef290463e78fb2b0000c60f4ad797e/raw/f640983249607e38af405c95c457ce4afc85c608/uvm_ioctl_override.c
#+end_src

#+begin_src sh
/compat/linux/bin/cc --sysroot=/compat/linux -m64 -std=c99 -Wall -ldl -fPIC -shared -o dummy-uvm.so uvm_ioctl_override.c
#+end_src

#+begin_src sh
mkdir -p ~/.config/gpu
cp dummy-uvm.so ~/.config/gpu
#+end_src

#+begin_src sh
/compat/linux/bin/bash
LD_PRELOAD="${HOME}/.config/gpu/dummy-uvm.so"
#+end_src

** miniconda

[[https://docs.anaconda.com/miniconda/install/#quick-command-line-install]]

#+begin_src sh
mkdir -p ~/documents/miniconda3
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/documents/miniconda3/miniconda.sh
chmod +x ~/documents/miniconda3/miniconda.sh
#+end_src

switch to the linuxulator bash shell

#+begin_src sh
/compat/linux/bin/bash
~/documents/miniconda3/miniconda.sh -b -u -p ~/documents/miniconda3
#+end_src

#+begin_src sh
rm ~/documents/miniconda3/miniconda.sh
#+end_src

activate miniconda

#+begin_src sh
source ~/documents/miniconda3/bin/activate
#+end_src

create the python env

#+begin_src sh
conda create -n comfyenv
conda activate comfyenv
#+end_src

#+begin_src sh
conda install pytorch torchvision torchaudio pytorch-cuda=12.4 -c pytorch -c nvidia
#+end_src

** git clone ComfyUI

#+begin_src sh
git clone https://github.com/comfyanonymous/ComfyUI.git
#+end_src

#+begin_src sh
cd CofmyUI
#+end_src

** pip install requirements

#+begin_src sh
pip install -r requirements.txt
#+end_src

** cuda torch check

#+begin_src sh
export CUDA_HOME="${HOME}/miniconda"
#+end_src

#+begin_src sh
source ~/miniconda3/bin/activate
conda activate comfyui
#+end_src

#+begin_src sh
python -c 'import torch; print(torch.cuda.is_available())'
LD_PRELOAD="${HOME}/.config/gpu/dummy-uvm.so" python -c 'import torch; print(torch.cuda.is_available())'
#+end_src

** run

#+begin_src sh
python main.py
#+end_src

** comfyui github

https://github.com/comfyanonymous/ComfyUI?tab=readme-ov-file

[[https://docs.comfy.org/get_started/manual_install#nvidia:install-nightly]]

[[https://docs.comfy.org/get_started/manual_install#nvidia]]

** conda deactivate comfyenv

#+begin_src sh
conda deactivate 
#+end_src

** conda remove comfyenv

#+begin_src sh
conda remove -n comfyenv --all
#+end_src

** uvm

#+begin_src c
#define _GNU_SOURCE

#include <dlfcn.h>
#include <fcntl.h>
#include <string.h>
#include <stdarg.h>
#include <stdint.h>

// pkg install linux-c7-devtools
// /compat/linux/bin/cc --sysroot=/compat/linux -m64 -std=c99 -Wall -ldl -fPIC -shared -o dummy-uvm.so uvm_ioctl_override.c
// env LD_PRELOAD=$PWD/dummy-uvm.so <cmd>

#define NV_UVM_INITIALIZE   0x30000001
#define NV_UVM_DEINITIALIZE 0x30000002

#define NV_ERR_NOT_SUPPORTED 0x56

struct NvUvmInitParams
{
  uint64_t flags __attribute__((aligned(8)));
  uint32_t status;
};

int (*libc_ioctl)(int fd, unsigned long request, ...) = NULL;

int ioctl(int fd, unsigned long request, ...) {

  if (!libc_ioctl) {
    libc_ioctl = dlsym(RTLD_NEXT, "ioctl");
  }

  va_list _args_;
  va_start(_args_, request);
  void* data = va_arg(_args_, void*);
  va_end(_args_);

  if (request == NV_UVM_INITIALIZE) {
    struct NvUvmInitParams* params = (struct NvUvmInitParams*)data;
    params->status = NV_ERR_NOT_SUPPORTED;
    return 0;
  }

  if (request == NV_UVM_DEINITIALIZE) {
    return 0;
  }

  return libc_ioctl(fd, request, data);
}

int (*libc_open)(const char* path, int flags, ...) = NULL;

int open(const char* path, int flags, ...) {

  if (!libc_open) { libc_open = dlsym(RTLD_NEXT, "open"); }

  mode_t mode = 0;

  va_list _args_;
  va_start(_args_, flags);

  if (flags & O_CREAT) {
    mode = va_arg(_args_, int);
  }

  va_end(_args_);

  if (strcmp("/dev/nvidia-uvm", path) == 0) {
    return libc_open("/dev/null", flags, mode);
  }

  return libc_open(path, flags, mode);  
}
#+end_src

** resources

[[https://developer.nvidia.com/cuda-12-4-0-download-archive?target_os=Linux&target_arch=x86_64&Distribution=Ubuntu&target_version=22.04&target_type=deb_local]]

[[https://docs.nvidia.com/cuda/cuda-installation-guide-linux/#meta-packages]]

[[https://github.com/verm/freebsd-stable-diffusion]]

** not used

#+begin_src sh
conda create -n comfyui python=3.12 --yes
conda activate comfyui
python --version
#+end_src


#+begin_src sh
conda install cuda -c nvidia
conda install cuda -c nvidia/label/cuda-12.4.0
#+end_src

#+begin_src sh
conda install pytorch torchvision torchaudio pytorch-cuda=12.4 -c pytorch -c nvidia/label/cuda-12.4.0
#+end_src

#+begin_src sh
conda install pytorch torchvision torchaudio pytorch-cuda=12.4 -c pytorch -c nvidia
#+end_src

