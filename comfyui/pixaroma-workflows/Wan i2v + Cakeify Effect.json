{
  "last_node_id": 74,
  "last_link_id": 111,
  "nodes": [
    {
      "id": 8,
      "type": "VAEDecode",
      "pos": [
        1230,
        180
      ],
      "size": [
        210,
        46
      ],
      "flags": {},
      "order": 15,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 35
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 76
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            94
          ],
          "slot_index": 0
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.18",
        "Node name for S&R": "VAEDecode"
      },
      "widgets_values": []
    },
    {
      "id": 54,
      "type": "CLIPVisionEncode",
      "pos": [
        170,
        660
      ],
      "size": [
        253.60000610351562,
        78
      ],
      "flags": {},
      "order": 12,
      "mode": 0,
      "inputs": [
        {
          "name": "clip_vision",
          "type": "CLIP_VISION",
          "link": 95
        },
        {
          "name": "image",
          "type": "IMAGE",
          "link": 96
        }
      ],
      "outputs": [
        {
          "name": "CLIP_VISION_OUTPUT",
          "type": "CLIP_VISION_OUTPUT",
          "links": [
            97
          ],
          "slot_index": 0
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.18",
        "Node name for S&R": "CLIPVisionEncode"
      },
      "widgets_values": [
        "none"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 7,
      "type": "CLIPTextEncode",
      "pos": [
        40,
        400
      ],
      "size": [
        425.27801513671875,
        180.6060791015625
      ],
      "flags": {},
      "order": 11,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 75
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            100
          ],
          "slot_index": 0
        }
      ],
      "title": "CLIP Text Encode (Negative Prompt)",
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.18",
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "Overexposure, static, blurred details, subtitles, paintings, pictures, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, mutilated, redundant fingers, poorly painted hands, poorly painted faces, deformed, disfigured, deformed limbs, fused fingers, cluttered background, three legs, a lot of people in the background, upside down"
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 48,
      "type": "VHS_VideoCombine",
      "pos": [
        1460,
        180
      ],
      "size": [
        214.7587890625,
        685.5819091796875
      ],
      "flags": {},
      "order": 16,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 94
        },
        {
          "name": "audio",
          "type": "AUDIO",
          "shape": 7,
          "link": null
        },
        {
          "name": "meta_batch",
          "type": "VHS_BatchManager",
          "shape": 7,
          "link": null
        },
        {
          "name": "vae",
          "type": "VAE",
          "shape": 7,
          "link": null
        }
      ],
      "outputs": [
        {
          "name": "Filenames",
          "type": "VHS_FILENAMES",
          "links": null
        }
      ],
      "properties": {
        "cnr_id": "comfyui-videohelpersuite",
        "ver": "4c7858ddd5126f7293dc3c9f6e0fc4c263cde079",
        "Node name for S&R": "VHS_VideoCombine"
      },
      "widgets_values": {
        "frame_rate": 16,
        "loop_count": 0,
        "filename_prefix": "WanVideo",
        "format": "video/h264-mp4",
        "pix_fmt": "yuv420p",
        "crf": 19,
        "save_metadata": true,
        "trim_to_audio": false,
        "pingpong": false,
        "save_output": true,
        "videopreview": {
          "hidden": false,
          "paused": false,
          "params": {
            "filename": "WanVideo_00009.mp4",
            "subfolder": "",
            "type": "output",
            "format": "video/h264-mp4",
            "frame_rate": 16,
            "workflow": "WanVideo_00009.png",
            "fullpath": "D:\\ComfyUI\\ComfyUI_windows_portable\\ComfyUI\\output\\WanVideo_00009.mp4"
          },
          "muted": false
        }
      }
    },
    {
      "id": 3,
      "type": "KSampler",
      "pos": [
        890,
        180
      ],
      "size": [
        315,
        262
      ],
      "flags": {},
      "order": 14,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 110
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 102
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 103
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 104
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            35
          ],
          "slot_index": 0
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.18",
        "Node name for S&R": "KSampler"
      },
      "widgets_values": [
        226086792672367,
        "randomize",
        30,
        6,
        "uni_pc",
        "simple",
        1
      ]
    },
    {
      "id": 66,
      "type": "UNETLoader",
      "pos": [
        -417.2535095214844,
        60.95886993408203
      ],
      "size": [
        432.59271240234375,
        82
      ],
      "flags": {},
      "order": 0,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            111
          ],
          "slot_index": 0
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.26",
        "Node name for S&R": "UNETLoader"
      },
      "widgets_values": [
        "wan2.1_i2v_480p_14B_fp8_scaled.safetensors",
        "default"
      ]
    },
    {
      "id": 38,
      "type": "CLIPLoader",
      "pos": [
        -380,
        320
      ],
      "size": [
        373.58380126953125,
        98.00001525878906
      ],
      "flags": {},
      "order": 1,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": [
            74,
            75
          ],
          "slot_index": 0
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.18",
        "Node name for S&R": "CLIPLoader"
      },
      "widgets_values": [
        "umt5_xxl_fp8_e4m3fn_scaled.safetensors",
        "wan",
        "default"
      ]
    },
    {
      "id": 55,
      "type": "WanImageToVideo",
      "pos": [
        528.3575439453125,
        198.20919799804688
      ],
      "size": [
        342.5999755859375,
        210
      ],
      "flags": {},
      "order": 13,
      "mode": 0,
      "inputs": [
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 99
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 100
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 101
        },
        {
          "name": "clip_vision_output",
          "type": "CLIP_VISION_OUTPUT",
          "shape": 7,
          "link": 97
        },
        {
          "name": "start_image",
          "type": "IMAGE",
          "shape": 7,
          "link": 98
        }
      ],
      "outputs": [
        {
          "name": "positive",
          "type": "CONDITIONING",
          "links": [
            102
          ],
          "slot_index": 0
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "links": [
            103
          ],
          "slot_index": 1
        },
        {
          "name": "latent",
          "type": "LATENT",
          "links": [
            104
          ],
          "slot_index": 2
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.18",
        "Node name for S&R": "WanImageToVideo"
      },
      "widgets_values": [
        480,
        832,
        65,
        1
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 39,
      "type": "VAELoader",
      "pos": [
        551.7909545898438,
        471.7908630371094
      ],
      "size": [
        306.36004638671875,
        58
      ],
      "flags": {},
      "order": 2,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "VAE",
          "type": "VAE",
          "links": [
            76,
            101
          ],
          "slot_index": 0
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.18",
        "Node name for S&R": "VAELoader"
      },
      "widgets_values": [
        "wan_2.1_vae.safetensors"
      ]
    },
    {
      "id": 52,
      "type": "CLIPVisionLoader",
      "pos": [
        -173.0079803466797,
        660
      ],
      "size": [
        315,
        58
      ],
      "flags": {},
      "order": 3,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "CLIP_VISION",
          "type": "CLIP_VISION",
          "links": [
            95
          ],
          "slot_index": 0
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.18",
        "Node name for S&R": "CLIPVisionLoader"
      },
      "widgets_values": [
        "clip_vision_h.safetensors"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 60,
      "type": "MarkdownNote",
      "pos": [
        -864.751953125,
        60.43171691894531
      ],
      "size": [
        428.2585144042969,
        938.7616577148438
      ],
      "flags": {
        "collapsed": false
      },
      "order": 4,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "Pixaroma - Note - Settings",
      "properties": {},
      "widgets_values": [
        "# 🎥 Recommended Settings for Wan 2.1  \n\n## ✅ Recommended Width and Height  \n### **480p**  \n- **Landscape (16:9)** → `832x480px`  \n- **Portrait (9:16)** → `480x832px`  \n- **Square (1:1)** → `640x640px`  \n\n---  \n\n## ✅ Recommended Length (Frames)  \n\n### **For 16 FPS:**  \n**Duration → Length Value (in the Latent Video Node)** \n- **1 second** → `17 frames`  \n- **2 seconds** → `33 frames`  \n- **3 seconds** → `49 frames`  \n- **4 seconds** → `65 frames`  \n- **5 seconds** → `81 frames`  \n\n### **For 24 FPS:**  \n**Duration → Length Value (in the Latent Video Node)**  \n- **1 second** → `25`  \n- **2 seconds** → `49`  \n- **3 seconds** → `73`  \n- **4 seconds** → `97`  \n- **5 seconds** → `121`  \n\n⚡ **16 FPS is generated faster than 24 FPS, but 24 FPS gives smoother motion.**  \n\n---  \n\n## ✅ Formula to Calculate Length  \n*(Remember to add an extra frame!)*  \n📌 **Formula:**  \n`Frames = (Seconds × FPS) + 1`  \n\n*(Check `frame_rate` in the **Video Combine Node**)  \n\n### **Example Calculations:**  \n📌 **For 3 seconds at 24 FPS:**  \n`(3 × 24) + 1 = 73 frames`  \n\n📌 **For 3 seconds at 16 FPS:**  \n`(3 × 16) + 1 = 49 frames`  \n\n---  \n\n## ✅ KSampler Settings  \n### **Recommended Steps:**  \n🔹 `15-30 steps` *(up to 50, try 30)*  \n\n### **Recommended CFG:**  \n🔹 `5-7` *(Try 6)*  \n\n---  \n\n## ✅ Recommended Frame Rate (**Video Combine Node**)  \n- **16 FPS** → ⏩ Faster generation, but less smooth motion  \n- **24 FPS** → 🕰️ Slower generation, but smoother video  \n\n📌 **If you change the frame rate, adjust the Length in the WanImageToVideo Node.**  \n"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 53,
      "type": "LoadImage",
      "pos": [
        -170,
        770
      ],
      "size": [
        315,
        314
      ],
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            96,
            98
          ],
          "slot_index": 0
        },
        {
          "name": "MASK",
          "type": "MASK",
          "links": null,
          "slot_index": 1
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.18",
        "Node name for S&R": "LoadImage"
      },
      "widgets_values": [
        "bunny 480x832 darkbg.jpg",
        "image"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 73,
      "type": "Note",
      "pos": [
        49.7825927734375,
        -358.6330871582031
      ],
      "size": [
        409.9794616699219,
        89.19393920898438
      ],
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "Lora trigger words to use in the prompt",
      "properties": {},
      "widgets_values": [
        "c4k3 cakeify it"
      ],
      "color": "#223",
      "bgcolor": "#335"
    },
    {
      "id": 72,
      "type": "Note",
      "pos": [
        46.58547592163086,
        -225.2680206298828
      ],
      "size": [
        409.1985168457031,
        224.36962890625
      ],
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "How to prompt",
      "properties": {},
      "widgets_values": [
        "Replace [object] with your subject\n\nThe video opens on a [object]. A knife, held by a hand, is coming into frame and hovering over the [object]. The knife then begins cutting into the [object] to c4k3 cakeify it. As the knife slices the [object] open, the inside of the [object] is revealed to be cake with chocolate layers. The knife cuts through and the contents of the [object] are revealed.\n\nExample:\nThe video opens on a bunny. A knife, held by a hand, is coming into frame and hovering over the bunny. The knife then begins cutting into the bunny to c4k3 cakeify it. As the knife slices the bunny open, the inside of the bunny is revealed to be cake with chocolate layers. The knife cuts through and the contents of the bunny are revealed."
      ],
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 6,
      "type": "CLIPTextEncode",
      "pos": [
        40,
        190
      ],
      "size": [
        422.84503173828125,
        164.31304931640625
      ],
      "flags": {},
      "order": 10,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 74
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            99
          ],
          "slot_index": 0
        }
      ],
      "title": "CLIP Text Encode (Positive Prompt)",
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.18",
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "The video opens on a bunny. A knife, held by a hand, is coming into frame and hovering over the bunny. The knife then begins cutting into the bunny to c4k3 cakeify it. As the knife slices the bunny open, the inside of the bunny is revealed to be cake with chocolate layers. The knife cuts through and the contents of the bunny are revealed."
      ],
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 59,
      "type": "MarkdownNote",
      "pos": [
        -1273.2386474609375,
        59.34428024291992
      ],
      "size": [
        384.4529113769531,
        784.0949096679688
      ],
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "Pixaroma - Note - Models Info - START HERE",
      "properties": {},
      "widgets_values": [
        "# MODELS USED IN THIS WORKFLOW  \n\n## ⚛️Load Diffusion Model \nDownload **wan2.1_i2v_480p_14B_fp8_scaled** from  \n[🔗 Direct Download](https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/diffusion_models/wan2.1_i2v_480p_14B_fp8_scaled.safetensors?download=true)  \n\n**Place in:** `ComfyUI/models/diffusion_models`  \n\nOr download a **bigger or smaller model** depending on your VRAM:  \n[📂 Model List](https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/tree/main/split_files/diffusion_models)  \n\n---  \n\n## 🟣Load CLIP  \nDownload **umt5_xxl_fp8_e4m3fn_scaled.safetensors** from  \n[🔗 Direct Download](https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/text_encoders/umt5_xxl_fp8_e4m3fn_scaled.safetensors?download=true)  \n\n**Place in:** `ComfyUI/models/text_encoders`  \n\n---  \n\n## 🟣Load CLIP Vision  \nDownload **clip_vision_h.safetensors** from  \n[🔗 Direct Download](https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/clip_vision/clip_vision_h.safetensors?download=true)  \n\n**Place in:** `ComfyUI/models/clip_vision`  \n\n---  \n\n## 🟣Load VAE  \nDownload **wan_2.1_vae.safetensors** from  \n[🔗 Direct Download](https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/vae/wan_2.1_vae.safetensors?download=true)  \n\n**Place in:** `ComfyUI/models/vae`  \n\n---\n---\n## 💜LoraLoaderModelOnly \nDownload **cakeify_16** from  \n[🔗 Direct Download](https://huggingface.co/Remade-AI/Cakeify/resolve/main/cakeify_16_epochs.safetensors?download=true)  \n\n**Place in:** `ComfyUI/models/loras`  \n\nOr you can download more loras from here:  \n[📂 Lora List](https://huggingface.co/collections/Remade-AI/wan21-14b-480p-i2v-loras-67d0e26f08092436b585919b)  \n\n---\n---\n\n## Nodes Installed from Manager\n\n**ComfyUI-VideoHelperSuite**\n\n\n## Resources  \n🎥 **Watch tutorials** on the [Pixaroma YouTube Channel](https://www.youtube.com/@pixaroma)  \n💬 **Join discussions** on [Discord](https://discord.com/invite/gggpkVgBf3)  \n"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 69,
      "type": "LoraLoaderModelOnly",
      "pos": [
        40,
        60
      ],
      "size": [
        418.13189697265625,
        82
      ],
      "flags": {},
      "order": 9,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 111
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            110
          ],
          "slot_index": 0
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.26",
        "Node name for S&R": "LoraLoaderModelOnly"
      },
      "widgets_values": [
        "cakeify_16_epochs.safetensors",
        1
      ],
      "color": "#223",
      "bgcolor": "#335"
    }
  ],
  "links": [
    [
      35,
      3,
      0,
      8,
      0,
      "LATENT"
    ],
    [
      74,
      38,
      0,
      6,
      0,
      "CLIP"
    ],
    [
      75,
      38,
      0,
      7,
      0,
      "CLIP"
    ],
    [
      76,
      39,
      0,
      8,
      1,
      "VAE"
    ],
    [
      94,
      8,
      0,
      48,
      0,
      "IMAGE"
    ],
    [
      95,
      52,
      0,
      54,
      0,
      "CLIP_VISION"
    ],
    [
      96,
      53,
      0,
      54,
      1,
      "IMAGE"
    ],
    [
      97,
      54,
      0,
      55,
      3,
      "CLIP_VISION_OUTPUT"
    ],
    [
      98,
      53,
      0,
      55,
      4,
      "IMAGE"
    ],
    [
      99,
      6,
      0,
      55,
      0,
      "CONDITIONING"
    ],
    [
      100,
      7,
      0,
      55,
      1,
      "CONDITIONING"
    ],
    [
      101,
      39,
      0,
      55,
      2,
      "VAE"
    ],
    [
      102,
      55,
      0,
      3,
      1,
      "CONDITIONING"
    ],
    [
      103,
      55,
      1,
      3,
      2,
      "CONDITIONING"
    ],
    [
      104,
      55,
      2,
      3,
      3,
      "LATENT"
    ],
    [
      110,
      69,
      0,
      3,
      0,
      "MODEL"
    ],
    [
      111,
      66,
      0,
      69,
      0,
      "MODEL"
    ]
  ],
  "groups": [],
  "config": {},
  "extra": {
    "ds": {
      "scale": 0.6934334949441839,
      "offset": [
        1352.253963485394,
        426.4238911793617
      ]
    },
    "VHS_latentpreview": false,
    "VHS_latentpreviewrate": 0,
    "VHS_MetadataImage": true,
    "VHS_KeepIntermediate": true
  },
  "version": 0.4
}