{
  "last_node_id": 16,
  "last_link_id": 15,
  "nodes": [
    {
      "id": 3,
      "type": "KSampler",
      "pos": {
        "0": 1210,
        "1": 50
      },
      "size": {
        "0": 315,
        "1": 262
      },
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 1
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 4
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 6
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 2
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            7
          ],
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "KSampler"
      },
      "widgets_values": [
        790965391452826,
        "randomize",
        30,
        7,
        "dpmpp_2m",
        "karras",
        1
      ]
    },
    {
      "id": 8,
      "type": "VAEDecode",
      "pos": {
        "0": 1560,
        "1": 50
      },
      "size": {
        "0": 210,
        "1": 46
      },
      "flags": {},
      "order": 9,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 7
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 8
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            9
          ],
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "VAEDecode"
      }
    },
    {
      "id": 7,
      "type": "CLIPTextEncode",
      "pos": {
        "0": 900,
        "1": 150
      },
      "size": [
        246.78114257964978,
        83.22048731631224
      ],
      "flags": {},
      "order": 4,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 5
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            6
          ],
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "ugly, watermark"
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 6,
      "type": "CLIPTextEncode",
      "pos": {
        "0": 920,
        "1": 60
      },
      "size": [
        422.84503173828125,
        164.31304931640625
      ],
      "flags": {
        "collapsed": true
      },
      "order": 7,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 3
        },
        {
          "name": "text",
          "type": "STRING",
          "link": 15,
          "widget": {
            "name": "text"
          }
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            4
          ],
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "closeup portrait of a sci-fi warrior robot, rusty metal, mech, cinematic, red eyes, dark interior background, movie scene, sharp, rim light, epic, golden hour"
      ],
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 5,
      "type": "EmptyLatentImage",
      "pos": {
        "0": 860,
        "1": 290
      },
      "size": {
        "0": 315,
        "1": 106
      },
      "flags": {},
      "order": 0,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            2
          ],
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "EmptyLatentImage"
      },
      "widgets_values": [
        1024,
        1024,
        1
      ],
      "color": "#323",
      "bgcolor": "#535"
    },
    {
      "id": 15,
      "type": "easy showAnything",
      "pos": {
        "0": 860,
        "1": 450
      },
      "size": [
        669.4478462373204,
        168.46298554074394
      ],
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [
        {
          "name": "anything",
          "type": "*",
          "link": 14
        }
      ],
      "outputs": [],
      "properties": {
        "Node name for S&R": "easy showAnything"
      },
      "widgets_values": [
        " The image shows a woman with long, curly red hair. She has fair skin and is looking directly at the camera. Her facial features are accentuated by her red lipstick. She appears to be wearing a dark top or dress that is not fully visible in the frame. The background is nondescript and out of focus, which draws attention to her. "
      ],
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 4,
      "type": "CheckpointLoaderSimple",
      "pos": {
        "0": 390,
        "1": 60
      },
      "size": {
        "0": 379.97589111328125,
        "1": 98
      },
      "flags": {},
      "order": 1,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            1
          ],
          "slot_index": 0
        },
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": [
            3,
            5
          ],
          "slot_index": 1
        },
        {
          "name": "VAE",
          "type": "VAE",
          "links": [
            8
          ],
          "slot_index": 2
        }
      ],
      "properties": {
        "Node name for S&R": "CheckpointLoaderSimple"
      },
      "widgets_values": [
        "Juggernaut_X_RunDiffusion.safetensors"
      ]
    },
    {
      "id": 9,
      "type": "SaveImage",
      "pos": {
        "0": 1561,
        "1": 165
      },
      "size": [
        445.03777557168314,
        493.3809680932063
      ],
      "flags": {},
      "order": 10,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 9
        }
      ],
      "outputs": [],
      "properties": {
        "Node name for S&R": "SaveImage"
      },
      "widgets_values": [
        "ComfyUI"
      ]
    },
    {
      "id": 14,
      "type": "LoadImage",
      "pos": {
        "0": 30,
        "1": 230
      },
      "size": [
        315,
        314
      ],
      "flags": {},
      "order": 2,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            13
          ],
          "shape": 3
        },
        {
          "name": "MASK",
          "type": "MASK",
          "links": null,
          "shape": 3
        }
      ],
      "properties": {
        "Node name for S&R": "LoadImage"
      },
      "widgets_values": [
        "PortraitWoman.png",
        "image"
      ]
    },
    {
      "id": 13,
      "type": "OllamaVision",
      "pos": {
        "0": 380,
        "1": 230
      },
      "size": {
        "0": 400,
        "1": 200
      },
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 13
        }
      ],
      "outputs": [
        {
          "name": "description",
          "type": "STRING",
          "links": [
            14,
            15
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "OllamaVision"
      },
      "widgets_values": [
        "describe the image",
        "enable",
        "http://127.0.0.1:11434",
        "llava:latest",
        5
      ],
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 16,
      "type": "Note",
      "pos": {
        "0": 383,
        "1": 477
      },
      "size": [
        395.47322424488334,
        381.3759966167188
      ],
      "flags": {},
      "order": 3,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {},
      "widgets_values": [
        "Use Vision Models - usually have llava in name\n\nExamples:\n\nllava phi 3  - 3.8b\n2.9 GB\nhttps://ollama.com/benzie/llava-phi-3\n\nllava 7b\n4.7 GB\nhttps://ollama.com/library/llava\n\nInstruction examples (choose one or create a similar one):\n\nDescribe the image\nor\nDescribe the image, add a black background\nor\nDescribe the image, use a vector art style\nor\nDescribe the image, make the subject wear a hat\nor\nDescribe the image, change the art style to macro photography\nor\nDescribe this vector illustration, start with a vector style illustration\n\nThe results may not always be perfectâ€”it depends on how well the model understands the instructions."
      ],
      "color": "#432",
      "bgcolor": "#653"
    }
  ],
  "links": [
    [
      1,
      4,
      0,
      3,
      0,
      "MODEL"
    ],
    [
      2,
      5,
      0,
      3,
      3,
      "LATENT"
    ],
    [
      3,
      4,
      1,
      6,
      0,
      "CLIP"
    ],
    [
      4,
      6,
      0,
      3,
      1,
      "CONDITIONING"
    ],
    [
      5,
      4,
      1,
      7,
      0,
      "CLIP"
    ],
    [
      6,
      7,
      0,
      3,
      2,
      "CONDITIONING"
    ],
    [
      7,
      3,
      0,
      8,
      0,
      "LATENT"
    ],
    [
      8,
      4,
      2,
      8,
      1,
      "VAE"
    ],
    [
      9,
      8,
      0,
      9,
      0,
      "IMAGE"
    ],
    [
      13,
      14,
      0,
      13,
      0,
      "IMAGE"
    ],
    [
      14,
      13,
      0,
      15,
      0,
      "*"
    ],
    [
      15,
      13,
      0,
      6,
      1,
      "STRING"
    ]
  ],
  "groups": [],
  "config": {},
  "extra": {
    "ds": {
      "scale": 1.1,
      "offset": [
        99.84361379101544,
        48.98488156316243
      ]
    }
  },
  "version": 0.4
}