#+STARTUP: content
* gpt-sovits nixos
** resources

[[https://github.com/RVC-Boss/GPT-SoVITS]]

** git clone gpt-sovits

#+begin_src sh
git clone https://github.com/RVC-Boss/GPT-SoVITS.git
cd GPT-SoVITS
#+end_src

** requirements.txt

comment out pyopenjtalk in the requirements.txt file

#+begin_src 
vi requirements.txt
#+end_src

#+begin_example
#pyopenjtalk>=0.4.1 # error
#+end_example

** shell.nix

#+begin_src nix
{ pkgs ? import <nixpkgs> {} }:

let
  pythonPackages = pkgs.python312Packages;
in
pkgs.mkShell {
  name = "gpt-sovits-env";
  # Increase stack size.
  NIX_SHELL_SET_LOCALE = "en_US.UTF-8";
  shellHook = ''
    echo "Entering nix-shell for GPT-SoVITS with CUDA 12."
    echo "Using the default CUDA version provided by nixpkgs (likely 12.x)."
    echo "Make sure your NVIDIA driver is compatible with CUDA 12.x."
    echo "If you run into issues, try increasing the stack size:"
    echo "ulimit -s unlimited"
    # Set the locale.
    export LC_ALL="en_US.UTF-8"
    export LANG="en_US.UTF-8"
    export PYTHONIOENCODING="utf-8"

    if [ ! -d ".venv" ]; then
      echo "Creating Python virtual environment using Nix-provided Python..."
      ${pkgs.python312}/bin/python3.12 -m venv .venv
    else
      echo "Re-activating existing Python virtual environment..."
    fi
    source .venv/bin/activate
    echo "Virtual environment activated."

    # Unset PYTHONPATH
    unset PYTHONPATH
    echo "PYTHONPATH unset."

    # Install torch without torchaudio first, from pip
    pip install torch -f https://download.pytorch.org/whl/torch_stable.html

    # Install the rest of the requirements
    if [ -f "requirements.txt" ]; then
      echo "Installing Python dependencies from requirements.txt..."
      pip install -r requirements.txt
    else
      echo "No requirements.txt found. Make sure it's in the same directory as shell.nix, or that you've cloned the GPT-SoVITS repo."
    fi
    echo "Python environment setup complete."
    echo "You can now run GPT-SoVITS."
    echo " "
  '';

  # Minimal buildInputs for CUDA 12
  buildInputs = [
    pkgs.git
    pkgs.wget
    pkgs.ffmpeg-full
    pkgs.cmake
    pkgs.gcc # Use pkgs.gcc directly
    pkgs.gnumake
    pkgs.coreutils
    pkgs.cacert # Certificate authority bundle
    pkgs.cudaPackages.cudatoolkit # Default CUDA (likely 12.x)
    pkgs.python312 # Ensure base python is available
    pythonPackages.setuptools
    pythonPackages.wheel
  ];

LD_LIBRARY_PATH = with pkgs;
        "${lib.makeLibraryPath [
          cudaPackages.cudatoolkit
          zlib
        ]}:${stdenv.cc.cc.lib}/lib";

}
#+end_src

** model-download.sh

save the model-download.sh script to the GPT-SoVITS directory

#+begin_example
model-download.sh
#+end_example

#+begin_src sh
#!/bin/sh

# Script to download GPT-SoVITS pretrained models.
# Intended to be run from the root of the GPT-SoVITS repository.

set -e

# Default values
is_HF=false
is_HF_MIRROR=false
is_MODELSCOPE=false
DOWNLOAD_UVR5=false
DOWNLOAD_WHISPER=false # Remove option to download Whisper model

# Function to display help
print_help() {
  echo "Usage: bash model-download.sh [OPTIONS]"
  echo ""
  echo "Options:"
  echo "  --source HF|HF-Mirror|ModelScope  Specify the model source (REQUIRED for some models)"
  echo "  --download-uvr5                   Enable downloading the UVR5 model"
  echo "  -h, --help                        Show this help message and exit"
  echo ""
  echo "Examples:"
  echo "  bash model-download.sh --source HF --download-uvr5"
  echo "  bash model-download.sh --source ModelScope"
}

# Check for arguments
if [[ $# -eq 0 ]]; then
  print_help
  exit 0
fi

# Use getopts to parse command-line arguments
while getopts "h-:" opt; do
  case "$opt" in
    -) # Long options
      case "$OPTARG" in
        source)
          case "$2" in
            HF)
              is_HF=true
              ;;
            HF-Mirror)
              is_HF_MIRROR=true
              ;;
            ModelScope)
              is_MODELSCOPE=true
              ;;
            ,*)
              echo "Error: Invalid Download Source: $2"
              echo "Choose From: [HF, HF-Mirror, ModelScope]"
              exit 1
              ;;
          esac
          shift
          ;;
        download-uvr5)
          DOWNLOAD_UVR5=true
          ;;
        help)
          print_help
          exit 0
          ;;
        ,*)
          echo "Unknown option: --$OPTARG"
          print_help
          exit 1
          ;;
      esac
      shift
      ;;
    h)
      print_help
      exit 0
      ;;
    ,*)
      echo "Unknown option: -$opt"
      print_help
      exit 1
      ;;
  esac
done
shift $((OPTIND -1))

# Check that --source was provided (modified to account for whisper)
if ! $is_HF && ! $is_HF_MIRROR && ! $is_MODELSCOPE; then # Removed check for DOWNLOAD_WHISPER
  echo "Error: Download Source is REQUIRED (--source)"
  echo ""
  print_help
  exit 1
fi

# Determine download URLs based on source
PRETRINED_URL=""
G2PW_URL=""
UVR5_URL=""
WHISPER_URL="https://huggingface.co/Systran/faster-whisper-large-v3" # Add Whisper URL - Not Used

if [ "$is_HF" = "true" ]; then
  echo "Downloading Model From HuggingFace"
  PRETRINED_URL="https://huggingface.co/lj1995/GPT-SoVITS" # Changed URL
  G2PW_URL="https://huggingface.co/XXXXRT/GPT-SoVITS-Pretrained/resolve/main/G2PWModel.zip"
  UVR5_URL="https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/uvr5_weights.zip" #changed URL
elif [ "$is_HF_MIRROR" = "true" ]; then
  echo "Downloading Model From HuggingFace-Mirror"
  PRETRINED_URL="https://hf-mirror.com/lj1995/GPT-SoVITS" # Changed URL
  G2PW_URL="https://hf-mirror.com/XXXXRT/GPT-SoVITS-Pretrained/resolve/main/G2PWModel.zip"
  UVR5_URL="https://hf-mirror.com/lj1995/VoiceConversionWebUI/resolve/main/uvr5_weights.zip" #changed URL
elif [ "$is_MODELSCOPE" = "true" ]; then
  echo "Downloading Model From ModelScope"
  PRETRINED_URL="https://www.modelscope.cn/models/XXXXRT/GPT-SoVITS-Pretrained/resolve/master/pretrained_models.zip"
  G2PW_URL="https://www.modelscope.cn/models/XXXXRT/GPT-SoVITS-Pretrained/resolve/master/G2PWModel.zip"
  UVR5_URL="https://www.modelscope.cn/models/XXXXRT/GPT-SoVITS-Pretrained/resolve/master/uvr5_weights.zip"
fi

# Download pretrained models if they don't exist
if [ "$is_HF" = "true" ] && [ ! -d "GPT_SoVITS/pretrained_models" ]; then # added source check
  echo "Downloading Pretrained Models..."
  git clone -q "$PRETRINED_URL" GPT_SoVITS/pretrained_models # Changed to git clone
fi

# Download G2PWModel if it doesn't exist
if [ "$is_HF" = "true" ] && [ ! -d "GPT_SoVITS/text/G2PWModel" ]; then # added source check
  echo "Downloading G2PWModel..."
  wget --show-progress -P GPT_SoVITS/text "$G2PW_URL" # Added --show-progress
  cd GPT_SoVITS/text || exit 1
  unzip -q G2PWModel.zip
  rm -f G2PWModel.zip
  cd ../..
fi

# Download UVR5 model if requested
if [ "$DOWNLOAD_UVR5" = "true" ] && [ ! -d "tools/uvr5/uvr5_weights" ]; then # Combined condition
  echo "Downloading UVR5 Model..."
  mkdir -p tools/uvr5
  wget --show-progress -P tools/uvr5 "$UVR5_URL" # Added --show-progress
  cd tools/uvr5 || exit 1
  unzip -q uvr5_weights.zip
  rm -f uvr5_weights.zip
  mv uvr5_weights/* uvr5_weights/
  rm -rf uvr5_weights
  cd ../..
fi

echo "Model download script completed."
#+end_src

make the script executable

#+begin_src sh
chmod +x ./model-download.sh
#+end_src

run the script to download the models

download uvr5

#+begin_src sh
./model-download.sh --source HF --download-uvr5
#+end_src

faster-whisper

[[https://huggingface.co/Systran/faster-whisper-large-v3]]

** webui

start the web ui

#+begin_src sh
python webui.py
#+end_src

optionally set the language

#+begin_src sh
python webui.py <language(optional)>
#+end_src

set the language to english

#+begin_src sh
python webui.py en
#+end_src
