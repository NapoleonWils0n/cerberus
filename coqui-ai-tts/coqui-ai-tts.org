#+STARTUP: content
* coqui-ai-TTS
** resources

[[https://github.com/idiap/coqui-ai-TTS]]

[[https://coqui-tts.readthedocs.io/en/latest/]]

** nixpkgs

create the nixpkgs directory

#+begin_src sh
mkdir -p ~/.config/nixpkgs
#+end_src

create the config.nix file

#+begin_src sh
vi ~/.config/nixpkgs/config.nix
#+end_src

with this code

#+begin_src nix
{ allowUnfree = true; }
#+end_src

** nix-shell

#+begin_src sh
vi ~/nix/tts/shell.nix
#+end_src

#+begin_src nix
{ pkgs ? import <nixpkgs> {} }:

pkgs.mkShell {
  buildInputs = [ pkgs.tts ];

  shellHook = ''
    echo "Coqui TTS environment loaded.  Run 'tts --help' for usage."
  '';
}
#+end_src

** nix-shell

#+begin_src sh
nix-shell
#+end_src

** tts list models

#+begin_src sh
tts --list_models
#+end_src

** tts-server

#+begin_src sh
tts-server -h
#+end_src

#+begin_example
2025-05-10 22:49:18.399145: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
#+end_example

#+begin_src sh
usage: tts-server [-h] [--list_models] [--model_name MODEL_NAME] [--vocoder_name VOCODER_NAME] [--config_path CONFIG_PATH]
                  [--model_path MODEL_PATH] [--vocoder_path VOCODER_PATH] [--vocoder_config_path VOCODER_CONFIG_PATH]
                  [--speakers_file_path SPEAKERS_FILE_PATH] [--port PORT] [--use_cuda | --no-use_cuda] [--debug | --no-debug]
                  [--show_details | --no-show_details]
#+end_src

#+begin_src sh
options:
  -h, --help            show this help message and exit
  --list_models         list available pre-trained tts and vocoder models.
  --model_name MODEL_NAME
                        Name of one of the pre-trained tts models in format <language>/<dataset>/<model_name>
  --vocoder_name VOCODER_NAME
                        name of one of the released vocoder models.
  --config_path CONFIG_PATH
                        Path to model config file.
  --model_path MODEL_PATH
                        Path to model file.
  --vocoder_path VOCODER_PATH
                        Path to vocoder model file. If it is not defined, model uses GL as vocoder. Please make sure that you installed vocoder
                        library before (WaveRNN).
  --vocoder_config_path VOCODER_CONFIG_PATH
                        Path to vocoder model config file.
  --speakers_file_path SPEAKERS_FILE_PATH
                        JSON file for multi-speaker model.
  --port PORT           port to listen on.
  --use_cuda, --no-use_cuda
                        true to use CUDA.
  --debug, --no-debug   true to enable Flask debug mode.
  --show_details, --no-show_details
                        Generate model detail page.
#+end_src

** tts

tts with cuda

*** default model

#+begin_src sh
tts --use_cuda --text "coqui-ai-TTS text to speech using cuda" --out_path output.wav
#+end_src

*** vits

#+begin_src sh
tts --use_cuda --text "Good day, mate! How's the weather in London?" --model_name "tts_models/en/vctk/vits" --out_path "british_vctk_vits.wav"
#+end_src

*** glow-tts

#+begin_src sh
tts --use_cuda --text "This is glow-tts using cuda" --model_name "tts_models/uk/mai/glow-tts" --out_path "british_mai_glow_tts.wav"
#+end_src

*** xtts_v2

#+begin_src sh
tts --model_name tts_models/multilingual/multi-dataset/xtts_v2 \
--text "To be or not to be, that is the question." \
--speaker_wav input.wav \
--language_idx en \
--use_cuda \
--out_path "xtts_v2_cloned_voice.wav"
#+end_src

*** bark

[[https://github.com/suno-ai/bark]]

large model

[[https://huggingface.co/suno/bark]]

small model

[[https://huggingface.co/suno/bark-small/tree/main]]

clone the small model

#+begin_src sh
git clone https://huggingface.co/suno/bark-small
#+end_src

download the model files with aria2c

#+begin_src sh
export SUNO_USE_SMALL_MODELS=True
#+end_src

#+begin_src sh
tts --model_name tts_models/multilingual/multi-dataset/bark \
--text "yes Yes People we are in for a big busy transfer window this summer.
What's going on everyone. Hope you are all good.
Welcome back to the Magpie Channel TV,Eddie House off a defiant message this morning in his press conference.
Finally for a change in all of this beating around the bush hiding behind things. Don't know how much we're going to spend." \
--speaker_wav input.wav \
--language_idx en \
--use_cuda \
--out_path "bark_cloned_voice.wav"
#+end_src

*** model info by name

#+begin_src sh
tts --model_info_by_name tts_models/multilingual/multi-dataset/xtts_v2
#+end_src
