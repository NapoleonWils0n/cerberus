#+STARTUP: content
* kokoro
** resources

[[https://github.com/hexgrad/kokoro]]

[[https://huggingface.co/hexgrad/Kokoro-82M]]

[[https://huggingface.co/hexgrad/Kokoro-82M/tree/main/voices]]

[[https://huggingface.co/spaces/hexgrad/Kokoro-TTS]]

** shell.nix

#+begin_src nix
{ pkgs ? import <nixpkgs> {} }:

let
  pythonPackages = pkgs.python312Packages;
in
pkgs.mkShell {
  name = "kokoro-tts";
  # Increase stack size.
  NIX_SHELL_SET_LOCALE = "en_US.UTF-8";
  shellHook = ''
    echo "ulimit -s unlimited"
    # Set the locale.
    export LC_ALL="en_US.UTF-8"
    export LANG="en_US.UTF-8"
    export PYTHONIOENCODING="utf-8"

    if [ ! -d ".venv" ]; then
      echo "Creating Python virtual environment using Nix-provided Python..."
      ${pkgs.python312}/bin/python3.12 -m venv .venv
    else
      echo "Re-activating existing Python virtual environment..."
    fi
    source .venv/bin/activate
    echo "Virtual environment activated."

    pip install -q "kokoro>=0.9.4" soundfile

    export CUDA_VISIBLE_DEVICES=0 # Or adjust if you have multiple GPUs
    export XDG_CACHE_HOME="$HOME/.cache" # Ensure a valid cache directory
    export PATH="$PATH:${pkgs.cudaPackages.cudatoolkit}/bin" # Corrected path. Adjust version as needed.
    export LD_LIBRARY_PATH="$LD_LIBRARY_PATH:${pkgs.cudaPackages.cudatoolkit}/lib:${pkgs.cudaPackages.cudatoolkit}/lib64:${pkgs.stdenv.cc.cc.lib}/lib" # Include stdenv

  '';

  # Minimal buildInputs for CUDA 12
  buildInputs = [
    pkgs.espeak
    pkgs.python312 # Ensure base python is available
    pythonPackages.setuptools
    pythonPackages.wheel
    pkgs.cudaPackages.cudatoolkit # Default CUDA (likely 12.x)
    pkgs.cudaPackages.cudnn
    pkgs.stdenv.cc.cc # Include the compiler
    pkgs.python312Packages.ipython
  ];
}
#+end_src

** british voices

female voices

#+begin_example
bf_alice.pt
bf_emma.pt
bf_isabella.pt
bf_lily.pt
#+end_example

male voices

#+begin_example
bm_daniel.pt
bm_fable.pt
bm_george.pt
bm_lewis.pt
#+end_example

** python script

usage:

#+begin_src sh
python kokoro-british.py -i input.txt -v bf_emma -o my_audio.wav
#+end_src

#+begin_src python
#!/usr/bin/env nix-shell
#!nix-shell -i python3 -p python3

from kokoro import KPipeline
import soundfile as sf
import torch
import getopt
import sys

def generate_speech(input_file, voice_name, output_file):
    """
    Generates speech from the text in the input file using Kokoro TTS
    and saves it to a single audio file.

    Args:
        input_file (str): Path to the text file.
        voice_name (str): Name of the voice to use.
        output_file (str): Path to the output audio file.
    """
    try:
        with open(input_file, 'r') as f:
            text = f.read()
    except FileNotFoundError:
        print(f"Error: Input file not found: {input_file}")
        sys.exit(1)

    pipeline = KPipeline(lang_code='b', repo_id='hexgrad/Kokoro-82M')
    audio_segments = []  # List to store audio segments
    generator = pipeline(text, voice=voice_name)

    for i, (gs, ps, audio) in enumerate(generator):
        print(i, gs, ps)
        audio_segments.append(audio) # Append the audio

    # Concatenate all audio segments into a single array
    audio_tensors = [torch.as_tensor(a.detach().clone()) for a in audio_segments] #create a list of tensors
    if audio_tensors: #check the list isn't empty
        full_audio = torch.cat(audio_tensors).numpy()
        sf.write(output_file, full_audio, 24000) # Write the combined audio
    else:
        print("No audio segments generated.  No output file created")
        sys.exit(1)

def main():
    """
    Main function to parse command-line arguments and generate speech.
    """
    input_file = None
    voice_name = 'bf_emma'  # Default voice
    output_file = 'output.wav' # Default output file

    try:
        opts, args = getopt.getopt(sys.argv[1:], "i:v:o:", ["input=", "voice=", "output="])
    except getopt.GetoptError as e:
        print(f"Error: {e}")
        print("Usage: python kokoro-test.py -i <input_file> [-v <voice_name>] [-o <output_file>]")
        sys.exit(1)

    for opt, arg in opts:
        if opt in ("-i", "--input"):
            input_file = arg
        elif opt in ("-v", "--voice"):
            voice_name = arg
        elif opt in ("-o", "--output"):
            output_file = arg

    if input_file is None:
        print("Error: Input file is required. Use -i <input_file>")
        sys.exit(1)

    generate_speech(input_file, voice_name, output_file)

if __name__ == "__main__":
    main()
#+end_src

** resample audio to 48000 khz

#+begin_src sh
ffmpeg -i input.wav -ar 48000 output.wav
#+end_src
