#+STARTUP: content
* whisperx nixos
** flake.nix

#+begin_src nix
{
  description = "A development shell for WhisperX with CUDA support (pip-based installation, targeting CUDA 12.x and cuDNN 8.x on NixOS 25.05).";

  inputs = {
    # Pinning to the latest stable NixOS 25.05 release
    nixpkgs.url = "github:NixOS/Nixpkgs/nixos-25.05";
    flake-utils.url = "github:numtide/flake-utils";
  };

  outputs = { self, nixpkgs, flake-utils }:
    flake-utils.lib.eachDefaultSystem (system:
      let
        pkgs = import nixpkgs {
          inherit system;
          config = {
            allowUnfree = true; # Necessary for NVIDIA drivers and CUDA
          };
        };
        # Resolve the cudnn_8_9 path at Nix evaluation time.
        # If attribute doesn't exist, getAttrFromPath returns null.
        cudnn89Path = pkgs.lib.getAttrFromPath [ "cudaPackages" "cudnn_8_9" "out" ] pkgs;
      in
      {
        devShells.default = pkgs.mkShell rec {
          name = "whisperx-dev";

          # Essential build inputs for CUDA and Python environment
          buildInputs = with pkgs; [
            python312 # Python interpreter for creating the venv
            stdenv.cc.cc.lib # C standard library
            stdenv.cc        # C compiler
            cudaPackages.cudatoolkit # Default CUDA toolkit from NixOS 25.05 (likely 12.x)
          ] ++ pkgs.lib.optionals (cudnn89Path != null) [ pkgs.cudaPackages.cudnn_8_9 ] # Conditionally include cudnn_8_9 if its path was resolved (not null)
          ++ [
            linuxPackages.nvidia_x11 # Host NVIDIA X11 drivers (for libcuda.so)
            zlib # Common dependency
          ];

          # Environment variables required for CUDA and library linking
          LD_LIBRARY_PATH = pkgs.lib.makeLibraryPath buildInputs;
          CUDA_PATH = pkgs.cudaPackages.cudatoolkit;
          CUDA_HOME = pkgs.cudaPackages.cudatoolkit;
          EXTRA_LDFLAGS = "-L${pkgs.linuxPackages.nvidia_x11}/lib";
          # Pass the resolved cuDNN 8.9 path to the shell. Convert null to empty string for shell.
          NIX_CUDNN_8_9_PATH = if cudnn89Path != null then toString cudnn89Path else "";

          # Ensure CUDA binaries (like nvidia-smi) are in PATH for diagnostics
          PATH = pkgs.lib.makeBinPath [
            pkgs.cudaPackages.cudatoolkit
          ];

          # Shell hook to set up the Python virtual environment and install dependencies
          shellHook = ''
            echo "Entering WhisperX development shell with CUDA support (NixOS 25.05 stable, PyTorch cu121/cu122, attempting cuDNN 8.9)..."
            echo "Note: PyTorch and WhisperX will be installed via pip within a virtual environment."

            # Set the locale for consistent encoding
            export LC_ALL="en_US.UTF-8"
            export LANG="en_US.UTF-8"
            export PYTHONIOENCODING="utf-8"

            # Create and activate Python virtual environment
            if [ ! -d ".venv" ]; then
              echo "Creating Python virtual environment..."
              ${pkgs.python312}/bin/python3.12 -m venv .venv
            else
              echo "Re-activating existing Python virtual environment..."
            fi
            source .venv/bin/activate
            echo "Virtual environment activated."

            # Set CUDA variables
            export CUDA_VISIBLE_DEVICES=0
            export XDG_CACHE_HOME="$HOME/.cache"

            # Upgrade pip
            pip install --upgrade pip

            # Install torch torchaudio for CUDA 12.1/12.2 (trying general cu12x)
            echo "Installing latest stable torch and torchaudio for CUDA 12.x..."
            pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu121
            # If cu121 still resolves to 12.6, we might try cu122 or no specific version
            # If problems persist, consider explicit torch versions that are known to work with cuDNN 8.x and CUDA 12.x
            # Example: pip install torch==2.1.2 torchaudio==2.1.2 --index-url https://download.pytorch.org/whl/cu121

            # Install whisperx
            echo "Installing whisperx..."
            pip install -U whisperx

            echo "WhisperX setup complete. You can now use 'whisperx' command."
          '';
        };
      });
}
#+end_src

** hugginface

create the huggingface directory if it doesnt exist

#+begin_src sh
mkdir -p ~/.cache/huggingface
#+end_src

create the token file and add your huggingface token to the file

#+begin_src sh
vi ~/.cache/huggingface/token
#+end_src

** nix develop

#+begin_src sh
nix develop
#+end_src

** nix flake update

#+begin_src sh
nix flake update
#+end_src

** whisperx usage

#+begin_src sh
whisperx input.wav --device cuda --model small --diarize --highlight_words True
#+end_src

** whisperx json

#+begin_src sh
whisperx input.mp4 --device cuda --model small --diarize --highlight_words True --output_format json,srt
#+end_src

** whisperx python script

#+begin_example
process_whisperx_output.py
#+end_example

#+begin_src python
import json
import os
import argparse
import re # Import regex for clean filename extraction

def format_timestamp(seconds):
    """Formats time in seconds to HH:MM:SS,ms for SRT/VTT."""
    ms = int((seconds - int(seconds)) * 1000)
    s = int(seconds % 60)
    m = int((seconds // 60) % 60)
    h = int(seconds // 3600)
    return f"{h:02}:{m:02}:{s:02},{ms:03}"

def format_vtt_timestamp(seconds):
    """Formats time in seconds to HH:MM:SS.ms for VTT."""
    ms = int((seconds - int(seconds)) * 1000)
    s = int(seconds % 60)
    m = int((seconds // 60) % 60)
    h = int(seconds // 3600)
    return f"{h:02}:{m:02}:{s:02}.{ms:03}"


def rename_speakers_in_json(input_json_path, output_json_path, speaker_map):
    """
    Reads a WhisperX JSON output file, renames speaker labels, and saves
    the updated JSON to a new file.

    Args:
        input_json_path (str): Path to the original WhisperX JSON output file.
        output_json_path (str): Path where the new JSON with renamed speakers
                                will be saved.
        speaker_map (dict): A dictionary mapping original speaker IDs (e.g.,
                            "SPEAKER_00") to desired names (e.g., "David").
    Returns:
        bool: True if successful, False otherwise.
    """
    try:
        with open(input_json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except FileNotFoundError:
        print(f"Error: Input JSON file not found at '{input_json_path}'")
        return False
    except json.JSONDecodeError:
        print(f"Error: Could not decode JSON from '{input_json_path}'. Is it valid JSON?")
        return False

    updated_segments = []
    for segment in data.get("segments", []):
        original_speaker_id = segment.get("speaker")
        
        # If a speaker ID exists and is in our map, replace it
        if original_speaker_id in speaker_map:
            segment["speaker"] = speaker_map[original_speaker_id]
        
        updated_segments.append(segment)

    data["segments"] = updated_segments

    try:
        os.makedirs(os.path.dirname(output_json_path), exist_ok=True)
        with open(output_json_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=4, ensure_ascii=False)
        print(f"Successfully renamed speakers and saved to '{output_json_path}'")
        return True
    except IOError as e:
        print(f"Error writing output file '{output_json_path}': {e}")
        return False


def convert_json_to_srt(input_json_path, output_srt_path):
    """
    Converts a JSON output (like from WhisperX, potentially with renamed speakers)
    into an SRT subtitle file.
    Returns:
        bool: True if successful, False otherwise.
    """
    try:
        with open(input_json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except FileNotFoundError:
        print(f"Error: Input JSON file not found at '{input_json_path}'")
        return False
    except json.JSONDecodeError:
        print(f"Error: Could not decode JSON from '{input_json_path}'. Is it valid JSON?")
        return False

    os.makedirs(os.path.dirname(output_srt_path), exist_ok=True)
    with open(output_srt_path, 'w', encoding='utf-8') as f:
        for i, segment in enumerate(data["segments"]):
            start_time = segment["start"]
            end_time = segment["end"]
            text = segment["text"].strip()
            speaker = segment.get("speaker", None)

            start_srt = format_timestamp(start_time)
            end_srt = format_timestamp(end_time)

            f.write(f"{i + 1}\n")
            f.write(f"{start_srt} --> {end_srt}\n")
            if speaker:
                f.write(f"[{speaker}]: {text}\n")
            else:
                f.write(f"{text}\n")
            f.write("\n")
    print(f"Successfully converted JSON to SRT: '{output_srt_path}'")
    return True

def convert_json_to_vtt(input_json_path, output_vtt_path):
    """
    Converts a JSON output into a VTT subtitle file.
    Returns:
        bool: True if successful, False otherwise.
    """
    try:
        with open(input_json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except FileNotFoundError:
        print(f"Error: Input JSON file not found at '{input_json_path}'")
        return False
    except json.JSONDecodeError:
        print(f"Error: Could not decode JSON from '{input_json_path}'. Is it valid JSON?")
        return False

    os.makedirs(os.path.dirname(output_vtt_path), exist_ok=True)
    with open(output_vtt_path, 'w', encoding='utf-8') as f:
        f.write("WEBVTT\n\n")
        for i, segment in enumerate(data["segments"]):
            start_time = segment["start"]
            end_time = segment["end"]
            text = segment["text"].strip()
            speaker = segment.get("speaker", None)

            start_vtt = format_vtt_timestamp(start_time)
            end_vtt = format_vtt_timestamp(end_time)

            f.write(f"{start_vtt} --> {end_vtt}\n")
            if speaker:
                f.write(f"<{speaker}> {text}\n") # VTT typically uses <speaker> format
            else:
                f.write(f"{text}\n")
            f.write("\n")
    print(f"Successfully converted JSON to VTT: '{output_vtt_path}'")
    return True


def convert_json_to_txt(input_json_path, output_txt_path):
    """
    Converts a JSON output (like from WhisperX, potentially with renamed speakers)
    into a plain text file with speaker labels.
    Returns:
        bool: True if successful, False otherwise.
    """
    try:
        with open(input_json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except FileNotFoundError:
        print(f"Error: Input JSON file not found at '{input_json_path}'")
        return False
    except json.JSONDecodeError:
        print(f"Error: Could not decode JSON from '{input_json_path}'. Is it valid JSON?")
        return False

    os.makedirs(os.path.dirname(output_txt_path), exist_ok=True)
    with open(output_txt_path, 'w', encoding='utf-8') as f:
        for segment in data["segments"]:
            text = segment["text"].strip()
            speaker = segment.get("speaker", None) # Get speaker, or None if not present

            if speaker:
                f.write(f"[{speaker}]: {text}\n")
            else:
                f.write(f"{text}\n")
    print(f"Successfully converted JSON to TXT: '{output_txt_path}'")
    return True


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="""Rename speakers in WhisperX JSON output and convert to SRT, VTT, and TXT.
        
        By default, output files are created in subdirectories (e.g., 'processed_srt')
        within the same directory as the input JSON file.
        
        Usage examples:
        # Output files created in subdirectories relative to the input JSON:
        python process_whisperx_output.py -j ~/Video/subtitles/video.json --map "SPEAKER_00=Host"
        
        # Output files created in a completely different, specified directory:
        python process_whisperx_output.py -j ~/Video/subtitles/video.json -o ./my_final_subtitles/ --map "SPEAKER_00=Guest"
        """,
        formatter_class=argparse.RawTextHelpFormatter # Keeps newlines in description
    )
    parser.add_argument(
        "-j", "--json_file", type=str, required=True,
        help="Path to the input WhisperX JSON file (e.g., ./whisperx_output/input.json)."
    )
    parser.add_argument(
        "-o", "--output_dir", type=str, default=None, # <--- Changed default to None
        help="Directory where output files (JSON, SRT, VTT, TXT) will be saved. "
             "If not specified, defaults to the directory of the input JSON file."
    )
    parser.add_argument(
        "--map", action="append", nargs=1, type=str, metavar="OLD_ID=NEW_NAME",
        help="Map an old speaker ID (e.g., 'SPEAKER_00') to a new name (e.g., 'David'). "
             "Use multiple times for multiple mappings: --map 'SPEAKER_00=David' --map 'SPEAKER_01=Oliver'."
    )
    args = parser.parse_args()

    # --- Configuration ---
    input_json = args.json_file
    
    # Determine the base output directory
    if args.output_dir:
        output_base_dir = args.output_dir
    else:
        # Default to the directory of the input JSON file
        output_base_dir = os.path.dirname(os.path.abspath(input_json))

    # Extract base filename without extension
    base_filename = os.path.splitext(os.path.basename(input_json))[0]
    
    # Ensure base_filename is clean for output paths
    base_filename = re.sub(r'[^a-zA-Z0-9_-]', '-', base_filename) 
    base_filename = base_filename.strip('-')

    # Define output file paths based on the base filename and the determined output_base_dir
    output_renamed_json = os.path.join(output_base_dir, "processed_json", f"{base_filename}-processed.json")
    output_renamed_srt = os.path.join(output_base_dir, "processed_srt", f"{base_filename}.srt")
    output_renamed_vtt = os.path.join(output_base_dir, "processed_vtt", f"{base_filename}.vtt")
    output_renamed_txt = os.path.join(output_base_dir, "processed_txt", f"{base_filename}.txt")

    # Construct speaker_name_map from command line arguments
    speaker_name_map = {}
    if args.map:
        for mapping_list in args.map: 
            mapping = mapping_list[0]
            if '=' in mapping:
                old_id, new_name = mapping.split('=', 1)
                speaker_name_map[old_id.strip()] = new_name.strip()
            else:
                print(f"Warning: Invalid speaker mapping format '{mapping}'. Expected 'OLD_ID=NEW_NAME'. Skipping.")
    
    if not speaker_name_map:
        print("No speaker mappings provided via --map. Using default generic speaker labels.")


    # --- Renaming Process ---
    print(f"Processing input JSON: '{input_json}'")
    renaming_successful = rename_speakers_in_json(input_json, output_renamed_json, speaker_name_map)

    if renaming_successful:
        # --- Generate SRT with Renamed Speakers ---
        print(f"\nGenerating SRT: '{output_renamed_srt}'")
        convert_json_to_srt(output_renamed_json, output_renamed_srt)

        # --- Generate VTT with Renamed Speakers ---
        print(f"\nGenerating VTT: '{output_renamed_vtt}'")
        convert_json_to_vtt(output_renamed_json, output_renamed_vtt)

        # --- Generate TXT with Renamed Speakers ---
        print(f"\nGenerating TXT: '{output_renamed_txt}'")
        convert_json_to_txt(output_renamed_json, output_renamed_txt)
    else:
        print("\nSkipping SRT, VTT, and TXT generation due to an error in JSON renaming.")
#+end_src

** python script usage

play the video with the srt file and identify the speakers

run the process_whisperx_output.py script with the -j option and the path to the json file

#+begin_src sh
python process_whisperx_output.py -j /path-to-json/video.json \
--map "SPEAKER_00=Oliver" \
--map "SPEAKER_01=David" \
--map "SPEAKER_02=Mike"
#+end_src
